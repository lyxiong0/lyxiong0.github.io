<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="普普通通">
<meta property="og:type" content="website">
<meta property="og:title" content="Xiong&#39;s Blog">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Xiong&#39;s Blog">
<meta property="og:description" content="普普通通">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Liyao Xiong">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Xiong's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Xiong's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Liyao Xiong">
      <meta itemprop="description" content="普普通通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiong's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week3/" class="post-title-link" itemprop="url">机器学习Week3</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-08-22 00:00:00" itemprop="dateCreated datePublished" datetime="2017-08-22T00:00:00+08:00">2017-08-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2017-08-29 16:48:38" itemprop="dateModified" datetime="2017-08-29T16:48:38+08:00">2017-08-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="分类问题（classification-problems）"><a href="#分类问题（classification-problems）" class="headerlink" title="分类问题（classification problems）"></a>分类问题（classification problems）</h2><p>y&#x3D;0 or 1</p>
<h3 id="回归分析-x2F-逻辑分析-logistic-regression"><a href="#回归分析-x2F-逻辑分析-logistic-regression" class="headerlink" title="回归分析&#x2F;逻辑分析(logistic regression):"></a>回归分析&#x2F;逻辑分析(logistic regression):</h3><p>目标：令h(x)位于[0,1]之间</p>
<h4 id="逻辑函数-x2F-S型函数"><a href="#逻辑函数-x2F-S型函数" class="headerlink" title="逻辑函数&#x2F;S型函数:"></a>逻辑函数&#x2F;S型函数:</h4><p><img src="http://i.imgur.com/ZjWOYQy.png"></p>
<p>图像:</p>
<p><img src="http://i.imgur.com/flCI9zQ.png"></p>
<p>x&#x3D;0，y&#x3D;0.5；x&#x3D;正无穷，y&#x3D;1；x&#x3D;负无穷，y&#x3D;0；</p>
<p>概率角度：P(y&#x3D;0|x;θ)+P(y&#x3D;1|x;θ)&#x3D;1，P(y&#x3D;1|x;θ)表示在给定x数值时y&#x3D;1的概率。</p>
<p>由图可知，要使得h&gt;0(y&#x3D;1),就要z&gt;0，所以是theta定义了决策边界，而训练集用于拟合参数theta</p>
<h3 id="一对多问题（One-vs-all）"><a href="#一对多问题（One-vs-all）" class="headerlink" title="一对多问题（One-vs-all）"></a>一对多问题（One-vs-all）</h3><p>若有个分类，则将问题分成n个1&#x2F;0简单分类问题。每个简单分类问题中，1代表n类中的一类，0代表剩余的n-1类。</p>
<p>计算出每个简单分类问题y&#x3D;1的概率，最终概率即为n个概率中该分类概率最大的。</p>
<p><img src="http://i.imgur.com/TxtyNGW.png"></p>
<h2 id="高级优化算法-Advanced-Optimization"><a href="#高级优化算法-Advanced-Optimization" class="headerlink" title="高级优化算法(Advanced Optimization)"></a>高级优化算法(Advanced Optimization)</h2><p>如：BFGS（变尺度法）、L-BFGS（限制变尺度法）、Conjugate gradient(共轭梯度法)</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>不用手动选择α，内部有智能的线性搜索算法（line search）,可以自动尝试各种α</li>
<li>速度比梯度下降法快</li>
<li>缺点只有复杂</li>
</ul>
<h3 id="在Matlab使用高级优化算法"><a href="#在Matlab使用高级优化算法" class="headerlink" title="在Matlab使用高级优化算法"></a>在Matlab使用高级优化算法</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[jVal, gradient]</span> = <span class="title">costFunction</span><span class="params">(theta)</span></span></span><br><span class="line">  jVal = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...]; <span class="comment">%J(theta)对theta偏导数</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(<span class="string">&#x27;GradObj&#x27;</span>, <span class="string">&#x27;on&#x27;</span>, <span class="string">&#x27;MaxIter&#x27;</span>, <span class="number">100</span>); <span class="comment">%储存option的数据结构，&#x27;GradObj&#x27;, &#x27;on&#x27;设置梯度目标参数为on打开，&#x27;MaxIter&#x27;, 100最大迭代次数。</span></span><br><span class="line">initialTheta = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">1</span>); <span class="comment">%theta的最初猜想值</span></span><br><span class="line">   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); <span class="comment">%fminunc是无约束最小化函数，@为指向costFunction的指针。</span></span><br></pre></td></tr></table></figure>

<p>运行结果中exitFlag&#x3D;1表示已经收敛，此时functionVal的值接近0</p>
<p><em>θ必须是二维及以上列向量</em></p>
<h2 id="过度拟合-overfitting"><a href="#过度拟合-overfitting" class="headerlink" title="过度拟合(overfitting)"></a>过度拟合(overfitting)</h2><p><img src="http://i.imgur.com/sYHIu2V.png"></p>
<p>图一表示未拟合(underfitting)或者HIgh bios(高偏差)；图三表示表示过度拟合或者高方差(hegh variance)。</p>
<p>定义：在有很多数据的情况下，曲线可能很好的拟合已有曲线。但是无法泛化(generate)新数据。</p>
<p>解决：1.减少选取的变量数。人工选取更重要的变量或者用模型选择算法自动选择变量。</p>
<p>2.正规化(regularization)</p>
<p>保存所有变量，不过减少数量级或者θ(j)的大小</p>
<h3 id="正规化"><a href="#正规化" class="headerlink" title="正规化"></a>正规化</h3><p>通过’惩罚’某些参数，可以使得曲线更加接近合适的曲线。为了使正规化更好的运行，需要选择合适的λ参数。</p>
<p><img src="http://i.imgur.com/wwybISj.png"></p>
<p>同样，正规化改变了J(θ)，也要改变梯度下降和正规方程算法中θ的递归式。在正规方程算法中，只要λ&gt;0，则矩阵可逆。</p>
<hr>
<p>正文结束</p>
<hr>
<p>一点吐槽：用了chrome和印象笔记快两年了，今天才发现印象笔记剪藏chrome插件有多好用，coursera上的文本基本都能一键收藏啊，还不用每次为了做笔记辛苦弄公式传图片。</p>
<p>大概以后就可以少写很多笔记了吧（各种偷懒）。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%94%99%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Liyao Xiong">
      <meta itemprop="description" content="普普通通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiong's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%94%99%E9%A2%98/" class="post-title-link" itemprop="url">机器学习错题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-08-22 00:00:00" itemprop="dateCreated datePublished" datetime="2017-08-22T00:00:00+08:00">2017-08-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2017-09-26 11:21:47" itemprop="dateModified" datetime="2017-09-26T11:21:47+08:00">2017-09-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ol>
<li>Suppose you have the following training set, and fit a logistic regression classifier hθ(x)&#x3D;g(θ0+θ1x1+θ2x2).</li>
</ol>
<p><img src="http://i.imgur.com/hIkTIJ8.png"></p>
<p><img src="http://i.imgur.com/jDYmKyf.png"></p>
<p>Which of the following are true? Check all that apply.</p>
<ul>
<li><p>J(θ) will be a convex function, so gradient descent should converge to the global minimum.</p>
</li>
<li><p>**Adding polynomial features (e.g., instead using hθ(x)&#x3D;g(θ0+θ1x1+θ2x2+θ3x21+θ4x1x2+θ5x22) ) could increase how well we can fit the training data. **</p>
</li>
<li><p>**The positive and negative examples cannot be separated using a straight line. So, gradient descent will fail to converge. **</p>
</li>
<li><p>Because the positive and negative examples cannot be separated using a straight line, linear regression will perform as well as logistic regression on this data.</p>
</li>
<li><p>**Adding polynomial features (e.g., instead using hθ(x)&#x3D;g(θ0+θ1x1+θ2x2+θ3x21+θ4x1x2+θ5x22) ) could increase how well we can fit the training data. **</p>
</li>
<li><p><strong>At the optimal value of θ (e.g., found by fminunc), we will have J(θ)≥0.</strong></p>
</li>
<li><p>Adding polynomial features (e.g., instead using hθ(x)&#x3D;g(θ0+θ1x1+θ2x2+θ3x21+θ4x1x2+θ5x22) ) would increase J(θ)because we are now summing over more terms.</p>
</li>
<li><p>If we train gradient descent for enough iterations, for some examples x(i) in the training set it is possible to obtain hθ(x(i))&gt;1.</p>
<p>​</p>
</li>
</ul>
<ol start="2">
<li>Which of the following statements are true? Check all that apply.</li>
</ol>
<ul>
<li><strong>The cost function J(θ) for logistic regression trained with m≥1 examples is always greater than or equal to zero.</strong></li>
<li>For logistic regression, sometimes gradient descent will converge to a local minimum (and fail to find the global minimum). This is the reason we prefer more advanced optimization algorithms such as fminunc (conjugate gradient&#x2F;BFGS&#x2F;L-BFGS&#x2F;etc).</li>
</ul>
<p><em>【解析】not for this reason, those three ads faster than gradient descent and you don’t need to manully pick alpha.</em></p>
<ul>
<li><strong>The one-vs-all technique allows you to use logistic regression for problems in which each y(i) comes from a fixed, discrete set of values.</strong></li>
<li>Since we train one classifier when there are two classes, we train two classifiers when there are three classes (and we do one-vs-all classification).</li>
</ul>
<p><em>【解析】we train one classifier for each class</em></p>
<ul>
<li><p>Linear regression always works well for classification if you classify by using a threshold on the prediction made by linear regression.</p>
</li>
<li><p><strong>The cost function J(θ) for logistic regression trained with m≥1 examples is always greater than or equal to zero.</strong></p>
</li>
<li><p><strong>The sigmoid function g(z)&#x3D;1&#x2F;(1+e^(−z)) is never greater than one (&gt;1).</strong></p>
<p>​</p>
</li>
</ul>
<ol start="3">
<li><p>Which of the following are reasons for using feature scaling?<br>It speeds up gradient descent by making it require fewer iterations to get to a good solution.<br><em>【解析】Feature scaling speeds up gradient descent by avoiding many extra iterations that are required when one or more features take on much larger values than the rest. The cost function J(θ) for linear regression has no local optima.The magnitude of the feature values are insignificant in terms of computational cost.</em> </p>
<p>​</p>
</li>
<li><p>You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.【D】</p>
<p>A. Introducing regularization to the model always results in equal or better performance on the training set.</p>
<p><em>【解析】If we introduce too much regularization, we can underfit the training set and have worse performance on the training set.</em></p>
<p>​           B.Adding many new features to the model helps prevent overfitting on the training set.</p>
<p><em>【解析】Adding many new features gives us more expressive models which are able to better fit our training set. If too many new features are added, this can lead to overfitting of the training set.</em></p>
<p>C. Adding a new feature to the model always results in equal or better performance on examples not in<br>the training set.</p>
<p><em>【解析】Adding  more features might result in a model that overfits the training set, and thus can lead to worse performs for examples which are not in the training set.</em></p>
<p><strong>D.Adding a new feature to the model always results in equal or better performance on the training set.</strong></p>
<p><em>【解析】By adding a new feature, our model must be more (or just as) expressive, thus allowing it learn more complex hypotheses to fit the training set.</em></p>
</li>
<li><p>Which of the following statements are true? Check all that apply.【ABD】</p>
<p>A. If a learning algorithm is suffering from high bias, only adding more training examples may <strong>not</strong> improve the test error significantly.</p>
<p>B. If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.</p>
<p>C. We always prefer models with high variance (over those with high bias) as they will able to better fit the training set.</p>
<p>D. When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem.</p>
</li>
<li><p>Which of the following statements are true? Check all that apply.【AC】</p>
<p>The “error analysis” process of manually examining the examples which your algorithm got wrong can help suggest what are good steps to take (e.g.,developing new features) to improve your algorithm’s performance.</p>
<p>It is a good idea to spend a lot of timecollecting a <strong>large</strong> amount of data before buildingyour first version of a learning algorithm.</p>
<p>Using a <strong>very large</strong> training setmakes it unlikely for model to overfit the trainingdata.</p>
<p>After training a logistic regressionclassifier, you <strong>must</strong> use 0.5 as your thresholdfor predicting whether an example is positive ornegative.</p>
<p>If your model is under fitting the training set, then obtaining more data is likely to help.</p>
</li>
<li><p>Suppose you have a dataset with n &#x3D; 10 features and m &#x3D; 5000 examples. After training your logistic regression classifier with gradient descent, you find that it has underfit the training set and does not achieve the desired performance on the training or cross validation sets. Which of the following might be promising steps to take? Check all that apply.</p>
<table>
<thead>
<tr>
<th>Your Answer</th>
<th align="center"></th>
<th align="center">Score</th>
<th align="left">Explanation</th>
</tr>
</thead>
<tbody><tr>
<td>Use a different optimization method since using gradient descent to train logistic regression might result in a local minimum.</td>
<td align="center">Not Correct</td>
<td align="center">0</td>
<td align="left">The logistic regression cost function is convex, so gradient descent will always find the global minimum.</td>
</tr>
<tr>
<td>Try using a neural network with a large number of hidden units.</td>
<td align="center">Correct</td>
<td align="center">0.5</td>
<td align="left">A neural network with many hidden units is a more complex (higher variance) model than logistic regression, so it is less likely to underfit the data.</td>
</tr>
<tr>
<td>Reduce the number of examples in the training set.</td>
<td align="center">Not Correct</td>
<td align="center">0</td>
<td align="left">While you can improve accuracy on the training set by removing examples, doing so results in a worse model that will not generalize as well.</td>
</tr>
<tr>
<td>Use an SVM with a Gaussian Kernel.</td>
<td align="center">Correct</td>
<td align="center">0.5</td>
<td align="left">By using a Gaussian kernel, your model will have greater complexity and can avoid underfitting the data.</td>
</tr>
</tbody></table>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Liyao Xiong">
      <meta itemprop="description" content="普普通通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiong's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week2/" class="post-title-link" itemprop="url">机器学习Week2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-08-17 14:38:12" itemprop="dateCreated datePublished" datetime="2017-08-17T14:38:12+08:00">2017-08-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2017-08-22 01:20:49" itemprop="dateModified" datetime="2017-08-22T01:20:49+08:00">2017-08-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一些缩写"><a href="#一些缩写" class="headerlink" title="一些缩写"></a>一些缩写</h2><p>n&#x3D;特征量的数目<br>x(i)&#x3D;第i行特征量的向量<br>x下标j上标i&#x3D;第i行第j个特征量<br>向量：nX1矩阵</p>
<h2 id="多变量的线性回归"><a href="#多变量的线性回归" class="headerlink" title="多变量的线性回归"></a>多变量的线性回归</h2><p>将Week1的梯度下降算法推广到多元向量上<br><img src="http://i.imgur.com/6QxnqDR.png"></p>
<h3 id="缩小范围加速梯度下降"><a href="#缩小范围加速梯度下降" class="headerlink" title="缩小范围加速梯度下降"></a>缩小范围加速梯度下降</h3><h4 id="特征缩放（Feature-scaling）"><a href="#特征缩放（Feature-scaling）" class="headerlink" title="特征缩放（Feature scaling）"></a>特征缩放（Feature scaling）</h4><p>由于特征值的范围会导致特征图是一个高瘦的椭圆形，不利于梯度下降的进行。所以通过将特征值除以其范围的上限，使得特征值范围在-1～1附近（不能过大或者过小），可以使得梯度下降更快且特征图接近圆形。</p>
<h4 id="均值归一化（Mean-normalization）"><a href="#均值归一化（Mean-normalization）" class="headerlink" title="均值归一化（Mean normalization）"></a>均值归一化（Mean normalization）</h4><p>将特征值减去平均值再除以总量（或标准差）。例如：房间大小在0～2000<img src="http://i.imgur.com/EWQeiVc.png"><br>使得所有特征量都有0的平均值  </p>
<h4 id="选择合适的学习率alpha"><a href="#选择合适的学习率alpha" class="headerlink" title="选择合适的学习率alpha"></a>选择合适的学习率alpha</h4><p>alpha也指梯度下降算法的更新规则，可以根据代价很熟随迭代步数增加的变化曲线来判断alpha是否过大或者过小。<br><img src="http://i.imgur.com/WT6iwnn.png"><br>图B表示过小，下降缓慢。<br>C为过大，几乎不下降，甚至有时上升。<br>A较为合适，下降较快。</p>
<h2 id="正规方程（Normal-equation）"><a href="#正规方程（Normal-equation）" class="headerlink" title="正规方程（Normal equation）"></a>正规方程（Normal equation）</h2><p>使用以下公式直接计算<br> <img src="http://i.imgur.com/ruRUVIe.png"><br>其中，X&#x3D;每一行为[1,特征向量x（i）的转置]，共有i行的矩阵。y&#x3D;[目标向量]的转置。<br>** 若出现矩阵不可逆，检查是否有多余特征值并删除 **</p>
<h2 id="正规方程与梯度下降法对比"><a href="#正规方程与梯度下降法对比" class="headerlink" title="正规方程与梯度下降法对比"></a>正规方程与梯度下降法对比</h2><h3 id="正规方程优缺点："><a href="#正规方程优缺点：" class="headerlink" title="正规方程优缺点："></a>正规方程优缺点：</h3><ul>
<li>不需要选择alpha</li>
<li>不需要缩小范围</li>
<li>复杂度为n的三次方（在n为10000内可以接受）</li>
<li>在特征量数目n很大的时候计算慢<h3 id="梯度下降法优缺点："><a href="#梯度下降法优缺点：" class="headerlink" title="梯度下降法优缺点："></a>梯度下降法优缺点：</h3></li>
<li>需要选择alpha</li>
<li>需要缩小范围</li>
<li>在特征量数目n很大的时候也可以运行的很好</li>
<li>复杂度为kn的平方</li>
</ul>
<h2 id="Matlab基础"><a href="#Matlab基础" class="headerlink" title="Matlab基础"></a>Matlab基础</h2><p>who：显示当前空间中所有变量名称</p>
<p>whos：显示当前空间中所有变量名称和详细信息</p>
<p>clear:清除</p>
<p>save 文件名.mat&#x2F;.txt 变量名：将变量保存到文件中。</p>
<p>load 文件名.mat&#x2F;.txt：将文件中的变量加载</p>
<p>** save load要注意当前所在文件位置;mat为一种压缩形式 **</p>
<h3 id="基础运算"><a href="#基础运算" class="headerlink" title="基础运算"></a>基础运算</h3><p>～&#x3D;不等于；&#x3D;&#x3D;等于；^n—n次方；&amp;&amp; 逻辑与；|| 逻辑或；XOR(  ,  ) 逻辑异或；abs（）绝对值；exp（）；log（）以10为底</p>
<h3 id="赋值"><a href="#赋值" class="headerlink" title="赋值"></a>赋值</h3><p>加上分号：不打印赋值；</p>
<p>字符串：a&#x3D;‘   ’</p>
<p>disp()：控制输出格式，例如disp(sprintf(‘   ‘,%0.2a))；类似C的格式，可以直接打印字符串</p>
<h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><h4 id="生成矩阵"><a href="#生成矩阵" class="headerlink" title="生成矩阵"></a>生成矩阵</h4><p>A&#x3D;[1 2; 3 4; 5 6]，分号表示切换到下一行，空格表示本行下一个数字。</p>
<p>递增行向量：a&#x3D;b:c:d，表示a为第一个数字是b，最后一个数字是d，依次以c递增。</p>
<p>c*ones(a,b):生成全为c的a行b列矩阵</p>
<p>zeros(a,b):生成a行b列0矩阵</p>
<p>rand(a,b)：生成随机位于（0,1）之间的a行b列矩阵。randn(a,b)：标准差为1的a行b列矩阵；</p>
<p>eye(a):生成a阶单位阵</p>
<p>A+a：A所有元素均加上a</p>
<p>A&#96;：A的转置矩阵</p>
<p>[a,b]&#x3D;max(A)(A为行向量)：a得到A中最大值，b为最大值所在位置的引索值；max（max（A））：找到整个A矩阵的最大元素</p>
<p>A&lt;a:依次判断每个元素是否小于a，得到一个和a行列数相同由1，0构成的矩阵</p>
<p>find(A&lt;a):找到小于a的元素，返回其引索值（从上到下，从左到右）</p>
<p>magic（a）：返回a阶的魔法矩阵。魔法矩阵：每行、每列、对角线相加都为同一个数</p>
<p>** 可以当作二重数组有A(a,b)或者A(a,b)的用法 **</p>
<h4 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h4><p>size(A)：返回矩阵大小，即返回一个1Xn矩阵；size(A,1):返回矩阵行数；size(A,2):返回矩阵列数</p>
<p>length(A):返回max(行数，列数)</p>
<p>A(a,b):引索到位于矩阵A的a行b列元素；A(a,:)：引索到A的a行所有元素，即返回一个1Xn矩阵。;A([a b];:)：取得A的第a行和第b行所有元素，返回2Xn矩阵。</p>
<p>A(:,a)&#x3D;B:将A矩阵的第a列替换为B列向量</p>
<p>C&#x3D;[A B]：将A B左右拼接生成C矩阵</p>
<p>C&#x3D;[A;B]：将A B上下拼接生成C</p>
<p>** AB不一定要为变量，可以是直接输入的矩阵，例如C&#x3D;[A;[1;2]] **</p>
<p>A(:)：将A矩阵中所有元素放入一个列向量</p>
<p>A.×B(点乘)：A、B必须为相同行列数的矩阵，生成的矩阵是A、B对应数相乘的结果。* A.^2可以使用，但A^2只能在A是方阵的前提下使用 *</p>
<p>sum(A):将A中所有元素相加；sum（A，1）：每列分别相加；sum（A，2）：每行分别相加</p>
<p>floor（A）：直接砍掉小数；ceil（A）：四舍五入的砍掉小数</p>
<h3 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h3><p>plot(a,b,c···):a参数表示x轴量，b表y轴，c表颜色之类可选项</p>
<p>xlabel（’ ‘）&#x2F;ylabel（’ ‘）：字符串命名x、y轴</p>
<p>legend（’ ‘,····）:标记曲线</p>
<p>title(‘ ‘):标记图表名字</p>
<p>figure(a):指定绘画</p>
<p>在第a张图上</p>
<p>subplot(a,b,c):将图标分成a*b的格子，显示并使用第c个格子</p>
<p>axis（[a b c d]）:设置x轴范围[a,b]，y轴范围[c,d];</p>
<p>clf：清除所有图像</p>
<p>imagesc(A)：用不同颜色显示A的元素，颜色相同则数值相同。连招：imagesc(A),colorbar,colormap gray:用灰度层显示A的元素。* 用逗号隔开的命令会依次执行 *</p>
<h3 id="控制语句"><a href="#控制语句" class="headerlink" title="控制语句"></a>控制语句</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=a:b,</span><br><span class="line">  something;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<p>有break、continue；</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="built_in">i</span>&lt;=a, <span class="comment">%可以直接填写while true/false,与break配合</span></span><br><span class="line">	something;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> a==b,</span><br><span class="line">	something;</span><br><span class="line"><span class="keyword">elseif</span> a~=b,</span><br><span class="line">	something;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	something;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>function [y1,y2,·····]&#x3D;函数名（x1,x2,·····） %y为返回值，x为变量名</p>
<p>something;</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Liyao Xiong">
      <meta itemprop="description" content="普普通通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiong's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Week1/" class="post-title-link" itemprop="url">机器学习Week1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-08-16 20:05:44" itemprop="dateCreated datePublished" datetime="2017-08-16T20:05:44+08:00">2017-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2018-09-01 21:44:42" itemprop="dateModified" datetime="2018-09-01T21:44:42+08:00">2018-09-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="课程中的一些缩写："><a href="#课程中的一些缩写：" class="headerlink" title="课程中的一些缩写："></a>课程中的一些缩写：</h2><p>m：训练集中样本的数目<br>x’s：输入变量&#x2F;特称变量<br>y’s：输出变量&#x2F;目标变量<br>（x(i),y(i)）:第i个变量<br>h:hypothesis（假设），表示算法输出的函数。一个特有名词，没有为什么，没有。</p>
<h2 id="机器学习的定义"><a href="#机器学习的定义" class="headerlink" title="机器学习的定义"></a>机器学习的定义</h2><p>A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as measured by P, improves with experience E.<br>Suppose we feed a learning algorithm a lot of historical weather<br>data, and have it learn to predict weather.</p>
<p>T–需要解决的任务，E–大量的数据（经验），P–性能度量值（评判标准）</p>
<h2 id="监督学习（Supervised-Learning）"><a href="#监督学习（Supervised-Learning）" class="headerlink" title="监督学习（Supervised Learning）"></a>监督学习（Supervised Learning）</h2><p>对于数据集中的每个数据， 都有相应的正确答案，（训练集） 算法就是基于这些来做出预测。分为** 回归问题（Regression） <strong>和</strong> 分类问题（Classification） **<br>回归问题：根据大量数据推测其他具体数据的情况<br>分类问题：是与否，例如：predict whether or not it will be raining at 5pm<br>tomorrow. </p>
<h2 id="无监督学习（Unsupervised-Learning）"><a href="#无监督学习（Unsupervised-Learning）" class="headerlink" title="无监督学习（Unsupervised Learning）"></a>无监督学习（Unsupervised Learning）</h2><p>只有一个一样数据集，没有属性或者标签，通过无监督学习可以判定该数据集所属的聚类（cluster）</p>
<h2 id="代价函数（Cost-Function）与梯度下降算法（Gradient-Descent）"><a href="#代价函数（Cost-Function）与梯度下降算法（Gradient-Descent）" class="headerlink" title="代价函数（Cost Function）与梯度下降算法（Gradient Descent）"></a>代价函数（Cost Function）与梯度下降算法（Gradient Descent）</h2><h3 id="代价函数（Cost-Function）"><a href="#代价函数（Cost-Function）" class="headerlink" title="代价函数（Cost Function）"></a>代价函数（Cost Function）</h3><p><img src="http://i.imgur.com/PMEpNDb.png"><br>目标即为求出最小参数值</p>
<h3 id="梯度下降算法（Gradient-Descent）"><a href="#梯度下降算法（Gradient-Descent）" class="headerlink" title="梯度下降算法（Gradient Descent）"></a>梯度下降算法（Gradient Descent）</h3><p><img src="http://i.imgur.com/0xJmq2X.png"><br>符号:&#x3D;表示将右值赋给左值，符号&#x3D;表示判断左右值是否相同<br>正确的更新方法为同步更新，而不是先更新一个参数再更新另一个参数。<br>α：学习速率（learning rate）表示算法的下降速率，过小导致算法速度太慢，太大容易略过最低点导致无法收敛甚至发散。<br>导数部分：由于斜率越接近谷底越小，所以不用改变alpha也可以下降到谷底。</p>
<h3 id="算法实例：用梯度下降的方法来最小化平方误差代价函数"><a href="#算法实例：用梯度下降的方法来最小化平方误差代价函数" class="headerlink" title="算法实例：用梯度下降的方法来最小化平方误差代价函数"></a>算法实例：用梯度下降的方法来最小化平方误差代价函数</h3><p><img src="http://i.imgur.com/A26A0MK.png"><br>梯度下降通常得到的是局部最优值，但由于用于** 线性回归的代价函数 <strong>总是一个</strong> 凸函数 **，所以使用梯度下降时只有一个全局最优解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/06/Linux%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Liyao Xiong">
      <meta itemprop="description" content="普普通通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiong's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/06/Linux%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">Linux 命令</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-08-06 23:07:07" itemprop="dateCreated datePublished" datetime="2017-08-06T23:07:07+08:00">2017-08-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2017-08-16 20:20:03" itemprop="dateModified" datetime="2017-08-16T20:20:03+08:00">2017-08-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h2><p>concatenate的缩写，用于访问单个或者多个文件。</p>
<h2 id="cowsay-XXX"><a href="#cowsay-XXX" class="headerlink" title="cowsay XXX"></a>cowsay XXX</h2><p>画一头说XXX的牛</p>
<h2 id="man-命令"><a href="#man-命令" class="headerlink" title="man 命令"></a>man 命令</h2><p>查看命令使用手册，调用了less程序，使内容整页显示。</p>
<h3 id="less程序"><a href="#less程序" class="headerlink" title="less程序"></a>less程序</h3><p>U——向上一整页，D——向下一整页，&lt;——回到开头，&gt;——跳到结尾<br>输入行数+ENTER——跳转到指定行数，&#x2F;字符串——搜索指定字符串（区分大小写），其中n跳到下一条，N上一条</p>
<h2 id="history-x2F-win-R-x2F-上箭头"><a href="#history-x2F-win-R-x2F-上箭头" class="headerlink" title="history&#x2F;win+R&#x2F;上箭头"></a>history&#x2F;win+R&#x2F;上箭头</h2><p>查看所有历史&#x2F;搜索历史&#x2F;调用上一条命令</p>
<h2 id="unzip"><a href="#unzip" class="headerlink" title="unzip"></a>unzip</h2><p>解压文件</p>
<h2 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h2><p>查看当前目录下所有文件,默认不输出以.开头的文件。<br>PS：以.开头的文件通常是系统文件<br>-a 不忽略.开头文件<br>-l 文件类型（目录 or 文件）&#x2F;？&#x2F;字节大小&#x2F;创建时间&#x2F;文件名.后缀</p>
<h2 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h2><p>remove移除文件<br>-rf r——recursive递归，f——force强制。 以递归的方式强制将目录下所有文件删除。</p>
<h2 id="ctrl-c"><a href="#ctrl-c" class="headerlink" title="ctrl+c"></a>ctrl+c</h2><p>停止当前操作</p>
<h2 id="ctrl-D"><a href="#ctrl-D" class="headerlink" title="ctrl+D"></a>ctrl+D</h2><p>表示文件结尾，用于结束输入或者退出程序</p>
<h2 id="nano"><a href="#nano" class="headerlink" title="nano"></a>nano</h2><p>调用Ubuntu自带文本编辑器nano</p>
<h2 id="pwd"><a href="#pwd" class="headerlink" title="pwd"></a>pwd</h2><p>查看当前所在目录</p>
<h2 id="cd"><a href="#cd" class="headerlink" title="cd"></a>cd</h2><p>进入某目录或文件夹，cd ..——返回父目录    .表示当前目录。<br>单独的cd表示返回主目录</p>
<h2 id="echo"><a href="#echo" class="headerlink" title="echo"></a>echo</h2><p>打印信息</p>
<h2 id="mv-x2F-cp"><a href="#mv-x2F-cp" class="headerlink" title="mv&#x2F;cp"></a>mv&#x2F;cp</h2><p>移动文件&#x2F;复制文件</p>
<h2 id="mkdir-目录"><a href="#mkdir-目录" class="headerlink" title="mkdir 目录"></a>mkdir 目录</h2><p>创建新目录</p>
<h2 id="rmdir"><a href="#rmdir" class="headerlink" title="rmdir"></a>rmdir</h2><p>删除目录，但仅用于删除空目录。<br>要删除有内容的目录，需要用到 ** rm -r **命令进行递归删除。</p>
<h1 id="Linux文件系统"><a href="#Linux文件系统" class="headerlink" title="Linux文件系统"></a>Linux文件系统</h1><h2 id="文件名"><a href="#文件名" class="headerlink" title="文件名"></a>文件名</h2><p>可以使用除了\以外的各种符号，但是如果使用了符号，在调用文件的时候就要用’文件名’来调用。</p>
<h2 id="根（root）"><a href="#根（root）" class="headerlink" title="根（root）"></a>根（root）</h2><p>Linux系统不像Windows系统每个分盘有独立的根，Linux所有文件属于一个根。要参考文件只能给出完整路径，用&#x2F;分割目录。</p>
<h2 id="glob（globbing通配符模式）"><a href="#glob（globbing通配符模式）" class="headerlink" title="glob（globbing通配符模式）"></a>glob（globbing通配符模式）</h2><p><em>XX</em> ，其中<em>代表匹配任意字符，可以放在字符串的任意位置，也可使用多个</em>。<br>XXX{A,B} 匹配包含花括号中任一字符串的文件，例如XXXA和XXXB。<br>？匹配一个字符，？？匹配两个字符····<br>[]匹配包含其中字母，注意只能匹配包含其中单个字母的文件，多个字母无需隔开。<br>** 以上匹配均区分大小写，且可跟在各种命令后 **</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liyao Xiong"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Liyao Xiong</p>
  <div class="site-description" itemprop="description">普普通通</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/lyxiong0" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lyxiong0" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liyao Xiong</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
